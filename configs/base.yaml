# --- Data Configuration ---
data:
  dataset: "data.datasets.CholecSeg8k"
  batch_size: 8
  num_workers: 4
  pin_memory: true

# --- Training Configuration ---
training:
  epochs: 10
  optimizer:
    name: "torch.optim.AdamW"
    params:
      lr: 0.0001
      weight_decay: 0.01
  scheduler:
    name: "torch.optim.lr_scheduler.ReduceLROnPlateau"
    params:
      mode: "min"
      factor: 0.1
      patience: 10

  checkpoint: null # continue training from this checkpoint
  finetune: null # finetune from this pre-trained model with frozen encoder

  encoder:
    name: "models.simple_unet.Encoder"
    params: {}

  tasks:
    segmentation:
      enabled: true
      criterion:
        weight: 1.0
        name: "monai.losses.DiceCELoss"
        params:
          sigmoid: True
      decoder:
        name: "models.simple_unet.SegmentationDecoder"
        params:
          num_classes: 2
      knowledge_distillation:
        enabled: false
        states: []
        criterion:
          weight: 0.5
          name: "torch.nn.KLDivLoss"
          params: {}
        encoder:
          name: "models.simple_unet.Encoder"
          params: {}
        decoder:
          name: "models.simple_unet.SegmentationDecoder"
          params: {}

    disparity: 
      enabled: false
      criterion:
        weight: 1.0
        name: null
        params: {}
      decoder:
        name: null # TODO: Implement disparity decoder
        params: {}
      knowledge_distillation:
        enabled: false
        states: []
        criterion:
          weight: 0.5
          name: null # ? L1Loss or MSELoss
          params: {}
        encoder:
          name: null
          params: {}
        decoder:
          name: null
          params: {}

logging:
  n_validation_images: 4