description: Base configuration

# --- Data Configuration ---
data:
  dataset: data.datasets.EndoVis17
  max_disparity: 320.0

  transforms:
    train:
      - name: Resize
        params:
          height: 256
          width: 256
      - name: Normalize
        params:
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]
    test:
      - name: Resize
        params:
          height: 256
          width: 256
      - name: Normalize
        params:
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]

  batch_size: 8
  num_workers: 4
  pin_memory: true

# --- Training Configuration ---
training:
  epochs: 10
  cross_validation: false

  optimizer:
    name: torch.optim.AdamW
    base_lr: 1.0e-3 # decoder and task heads learning rate
    encoder_lr_mod: 0.1 # dont let pretrained encoder explode
    params:
      weight_decay: 0.01

  scheduler:
    name: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts
    params:
      T_0: 50
      T_mult: 1
      eta_min: 1.0e-7

  checkpoint: null # continue training from this checkpoint
  finetune: null # finetune from this pre-trained model with frozen encoder

  encoder:
    name: models.encoders.timm.Encoder
    params: {}

  tasks:
    segmentation:
      enabled: true
      criterion:
        name: monai.losses.DiceCELoss
        params:
          softmax: true
          to_onehot_y: true
          include_background: false
      decoder:
        name: models.decoders.dynamic_unet.Decoder
        params: {}
      knowledge_distillation:
        enabled: false
        states: []
        criterion:
          weight: 0.5
          name: torch.nn.KLDivLoss
          params: {}
        encoder:
          name: models.encoders.timm.Encoder
          params: {}
        decoder:
          name: models.decoders.dynamic_unet.Decoder
          params: {}

    disparity: 
      enabled: true
      criterion:
        name: criterions.disparity.MaskedSmoothL1Loss
        params:
          ignore_value: 0
          reduction: mean
          beta: 1.0
      decoder:
        name: models.decoders.dynamic_unet.Decoder
        params:
          is_stereo: true
      knowledge_distillation:
        enabled: false
        states: []
        criterion:
          weight: 0.5
          name: torch.nn.KLDivLoss
          params: {}
        encoder:
          name: models.encoders.timm.Encoder
          params: {}
        decoder:
          name: models.decoders.dynamic_unet.Decoder
          params: {}

logging:
  vram: false
  notebook_mode: false
  n_validation_images: 4